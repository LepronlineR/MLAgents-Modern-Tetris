{
    "name": "root",
    "gauges": {
        "TetrisPPO.Policy.Entropy.mean": {
            "value": 2.4546074867248535,
            "min": 2.447849750518799,
            "max": 2.4840762615203857,
            "count": 814
        },
        "TetrisPPO.Policy.Entropy.sum": {
            "value": 23485.68359375,
            "min": 20348.76953125,
            "max": 30524.12109375,
            "count": 814
        },
        "TetrisPPO.Step.mean": {
            "value": 8139997.0,
            "min": 9984.0,
            "max": 8139997.0,
            "count": 814
        },
        "TetrisPPO.Step.sum": {
            "value": 8139997.0,
            "min": 9984.0,
            "max": 8139997.0,
            "count": 814
        },
        "TetrisPPO.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.06304335594177246,
            "min": -0.21774424612522125,
            "max": 0.08375928550958633,
            "count": 814
        },
        "TetrisPPO.Policy.ExtrinsicValueEstimate.sum": {
            "value": -4.980424880981445,
            "min": -16.984050750732422,
            "max": 6.616983413696289,
            "count": 814
        },
        "TetrisPPO.Policy.GailValueEstimate.mean": {
            "value": 15.224502563476562,
            "min": -0.3640497028827667,
            "max": 20.43271827697754,
            "count": 814
        },
        "TetrisPPO.Policy.GailValueEstimate.sum": {
            "value": 1202.7357177734375,
            "min": -28.759925842285156,
            "max": 1614.184814453125,
            "count": 814
        },
        "TetrisPPO.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 814
        },
        "TetrisPPO.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 814
        },
        "TetrisPPO.Environment.EpisodeLength.mean": {
            "value": 6632.0,
            "min": 3199.0,
            "max": 9982.333333333334,
            "count": 673
        },
        "TetrisPPO.Environment.EpisodeLength.sum": {
            "value": 13264.0,
            "min": 3199.0,
            "max": 38993.0,
            "count": 673
        },
        "TetrisPPO.Environment.CumulativeReward.mean": {
            "value": -4.718000017805025,
            "min": -4.829500411637127,
            "max": 16.60016561873878,
            "count": 673
        },
        "TetrisPPO.Environment.CumulativeReward.sum": {
            "value": -9.43600003561005,
            "min": -33.11850072443485,
            "max": 49.80049685621634,
            "count": 673
        },
        "TetrisPPO.Policy.ExtrinsicReward.mean": {
            "value": -4.718000017805025,
            "min": -4.829500411637127,
            "max": 16.60016561873878,
            "count": 673
        },
        "TetrisPPO.Policy.ExtrinsicReward.sum": {
            "value": -9.43600003561005,
            "min": -33.11850072443485,
            "max": 49.80049685621634,
            "count": 673
        },
        "TetrisPPO.Policy.GailReward.mean": {
            "value": 1034.5240861859638,
            "min": 200.01546144788153,
            "max": 2417.0058670043945,
            "count": 673
        },
        "TetrisPPO.Policy.GailReward.sum": {
            "value": 2069.0481723719276,
            "min": 200.01546144788153,
            "max": 12284.224602222443,
            "count": 673
        },
        "TetrisPPO.Losses.PolicyLoss.mean": {
            "value": 0.19805775799386538,
            "min": 0.15265711665603884,
            "max": 0.27119975615453584,
            "count": 19
        },
        "TetrisPPO.Losses.PolicyLoss.sum": {
            "value": 0.19805775799386538,
            "min": 0.15265711665603884,
            "max": 0.27119975615453584,
            "count": 19
        },
        "TetrisPPO.Losses.ValueLoss.mean": {
            "value": 0.8747836425376591,
            "min": 0.8493392625821289,
            "max": 1.8498900095284916,
            "count": 19
        },
        "TetrisPPO.Losses.ValueLoss.sum": {
            "value": 0.8747836425376591,
            "min": 0.8493392625821289,
            "max": 1.8498900095284916,
            "count": 19
        },
        "TetrisPPO.Policy.LearningRate.mean": {
            "value": 2.2590284104900003e-06,
            "min": 2.2590284104900003e-06,
            "max": 9.592375076290003e-06,
            "count": 19
        },
        "TetrisPPO.Policy.LearningRate.sum": {
            "value": 2.2590284104900003e-06,
            "min": 2.2590284104900003e-06,
            "max": 9.592375076290003e-06,
            "count": 19
        },
        "TetrisPPO.Policy.Epsilon.mean": {
            "value": 0.14517902000000005,
            "min": 0.14517902000000005,
            "max": 0.29184741999999997,
            "count": 19
        },
        "TetrisPPO.Policy.Epsilon.sum": {
            "value": 0.14517902000000005,
            "min": 0.14517902000000005,
            "max": 0.29184741999999997,
            "count": 19
        },
        "TetrisPPO.Policy.Beta.mean": {
            "value": 0.0022666920490000005,
            "min": 0.0022666920490000005,
            "max": 0.009592778628999998,
            "count": 19
        },
        "TetrisPPO.Policy.Beta.sum": {
            "value": 0.0022666920490000005,
            "min": 0.0022666920490000005,
            "max": 0.009592778628999998,
            "count": 19
        },
        "TetrisPPO.Policy.GAILPolicyEstimate.mean": {
            "value": 0.24062127908342518,
            "min": 0.23601327001850586,
            "max": 0.3464768872456625,
            "count": 19
        },
        "TetrisPPO.Policy.GAILPolicyEstimate.sum": {
            "value": 0.24062127908342518,
            "min": 0.23601327001850586,
            "max": 0.3464768872456625,
            "count": 19
        },
        "TetrisPPO.Policy.GAILExpertEstimate.mean": {
            "value": 0.7822317562401294,
            "min": 0.6367525405138731,
            "max": 0.7822317562401294,
            "count": 19
        },
        "TetrisPPO.Policy.GAILExpertEstimate.sum": {
            "value": 0.7822317562401294,
            "min": 0.6367525405138731,
            "max": 0.7822317562401294,
            "count": 19
        },
        "TetrisPPO.Losses.GAILLoss.mean": {
            "value": 0.5790693838335573,
            "min": 0.5751306465268136,
            "max": 0.9296570522040128,
            "count": 19
        },
        "TetrisPPO.Losses.GAILLoss.sum": {
            "value": 0.5790693838335573,
            "min": 0.5751306465268136,
            "max": 0.9296570522040128,
            "count": 19
        },
        "TetrisPPO.Policy.GAILGradMagLoss.mean": {
            "value": 0.02643557866779156,
            "min": 0.024787169012764933,
            "max": 0.10552412450115663,
            "count": 19
        },
        "TetrisPPO.Policy.GAILGradMagLoss.sum": {
            "value": 0.02643557866779156,
            "min": 0.024787169012764933,
            "max": 0.10552412450115663,
            "count": 19
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1670792606",
        "python_version": "3.8.13 (default, Sep 16 2022, 11:25:45) [MSC v.1900 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\getog\\AppData\\Local\\Programs\\Python\\Python38\\Scripts\\mlagents-learn config/agent-config.yaml --run-id TetrisPPO --force",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1670804821"
    },
    "total": 12214.3688508,
    "count": 1,
    "self": 0.007223499998872285,
    "children": {
        "run_training.setup": {
            "total": 0.07772880000000004,
            "count": 1,
            "self": 0.07772880000000004
        },
        "TrainerController.start_learning": {
            "total": 12214.2838985,
            "count": 1,
            "self": 2.8105029998041573,
            "children": {
                "TrainerController._reset_env": {
                    "total": 18.1754489,
                    "count": 1,
                    "self": 5.827638499999999,
                    "children": {
                        "demo_to_buffer": {
                            "total": 12.3478104,
                            "count": 1,
                            "self": 0.00031700000000256523,
                            "children": {
                                "load_demonstration": {
                                    "total": 0.24004700000000057,
                                    "count": 1,
                                    "self": 0.23197270000000092,
                                    "children": {
                                        "read_file": {
                                            "total": 0.008074299999999646,
                                            "count": 1,
                                            "self": 0.008074299999999646
                                        }
                                    }
                                },
                                "make_demo_buffer": {
                                    "total": 12.107446399999997,
                                    "count": 1,
                                    "self": 2.074266399999914,
                                    "children": {
                                        "steps_from_proto": {
                                            "total": 10.033180000000083,
                                            "count": 107088,
                                            "self": 6.525864500000586,
                                            "children": {
                                                "_process_rank_one_or_two_observation": {
                                                    "total": 3.507315499999497,
                                                    "count": 214176,
                                                    "self": 3.507315499999497
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController.advance": {
                    "total": 12193.197939400196,
                    "count": 254691,
                    "self": 2.900676900793769,
                    "children": {
                        "env_step": {
                            "total": 1748.7274065002111,
                            "count": 254691,
                            "self": 1374.8438305996485,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 372.0199972001271,
                                    "count": 254691,
                                    "self": 15.478483800329741,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 356.54151339979734,
                                            "count": 254691,
                                            "self": 356.54151339979734
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.8635787004355855,
                                    "count": 254691,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 12112.990023900124,
                                            "count": 254691,
                                            "is_parallel": true,
                                            "self": 11089.020078399857,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0008745000000001113,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00024629999999969954,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0006282000000004118,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0006282000000004118
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1023.969071000266,
                                                    "count": 254691,
                                                    "is_parallel": true,
                                                    "self": 55.12952640039623,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 87.47062570012541,
                                                            "count": 254691,
                                                            "is_parallel": true,
                                                            "self": 87.47062570012541
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 731.8847702998347,
                                                            "count": 254691,
                                                            "is_parallel": true,
                                                            "self": 731.8847702998347
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 149.48414859990962,
                                                            "count": 254691,
                                                            "is_parallel": true,
                                                            "self": 34.12757940053575,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 115.35656919937387,
                                                                    "count": 509382,
                                                                    "is_parallel": true,
                                                                    "self": 115.35656919937387
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 10441.56985599919,
                            "count": 254691,
                            "self": 8.183758499168107,
                            "children": {
                                "process_trajectory": {
                                    "total": 692.0241145000219,
                                    "count": 254691,
                                    "self": 680.0472152000236,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 11.976899299998287,
                                            "count": 162,
                                            "self": 11.976899299998287
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 9741.361983,
                                    "count": 20,
                                    "self": 2427.3983133001557,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 7313.963669699845,
                                            "count": 153429,
                                            "self": 7313.963669699845
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.999995770864189e-07,
                    "count": 1,
                    "self": 8.999995770864189e-07
                },
                "TrainerController._save_models": {
                    "total": 0.10000630000104138,
                    "count": 1,
                    "self": 0.018475599999874248,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.08153070000116713,
                            "count": 1,
                            "self": 0.08153070000116713
                        }
                    }
                }
            }
        }
    }
}